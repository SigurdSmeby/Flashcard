type,topic,question,answer,options,correctOption,explanation
mc,"Lecture 2","Hva er forskjellen mellom et problem og en problem-instans innenfor algoritmer?",,"Et problem er vanskeligere √• l√∏se enn en problem-instans|Et problem er en generell beskrivelse, mens en problem-instans er et spesifikt tilfelle med konkrete inndata|Et problem krever alltid en algoritme, mens en problem-instans kan l√∏ses manuelt|Et problem har kun √©n l√∏sning, mens en problem-instans kan ha flere l√∏sninger",1,"Et problem er en generell beskrivelse av hva inndataene ser ut som og hva den √∏nskede utdataen skal v√¶re, for eksempel sortering av en liste. En problem-instans er et spesifikt tilfelle av problemet med konkrete inndata, som for eksempel listen [3, 9, 1, 42, 17]."
mc,"Lecture 2","Forklar hva asymptotisk notasjon brukes til i forbindelse med algoritmeanalyse.",,"For √• m√•le n√∏yaktig kj√∏retid i sekunder for alle typer algoritmer|For √• analysere hvordan kj√∏retiden oppf√∏rer seg|For √• telle antall linjer kode i en algoritme|For √• sammenligne konstante faktorer mellom algoritmer",1,"Asymptotisk notasjon er et verkt√∏y for √• analysere hvordan kj√∏retiden til en algoritme (eller veksten til en matematisk funksjon) oppf√∏rer seg n√•r st√∏rrelsen p√• inndataene blir veldig stor. Det hjelper oss med √• sammenligne effektiviteten til forskjellige algoritmer ved √• fokusere p√• den dominerende veksttermen og ignorere konstante faktorer og lavere ordens termer."
qa,"Lecture 2","Nevn og beskriv kort de tre hovedkategoriene av asymptotisk notasjon som ble presentert.","Big-O notasjon (ùëÇ) gir en √∏vre grense for veksten til en funksjon; ùëì(ùëõ) = ùëÇ(ùëî(ùëõ)) betyr at ùëì ikke vokser raskere enn ùëî. Big-omega notasjon (Œ©) gir en nedre grense; ùëì(ùëõ) = Œ©(ùëî(ùëõ)) betyr at ùëì ikke vokser saktere enn ùëî. Big-theta notasjon (Œò) betyr at to funksjoner vokser i samme takt; ùëì(ùëõ) = Œò(ùëî(ùëõ)) betyr at ùëì og ùëî har samme vekstrate.",,,
qa,"Lecture 2","Hva er den typiske strukturen som kjennetegner sorteringsalgoritmer med kvadratisk tidskompleksitet?","Kvadratiske sorteringsalgoritmer har typisk to n√∏stede l√∏kker der begge l√∏kkene itererer over (omtrent) alle elementene i inndataene. Dette resulterer i et antall operasjoner som er proporsjonalt med kvadratet av inndatast√∏rrelsen (ùëõ¬≤).",,,
qa,"Lecture 2","Hvorfor har sammenligningsbaserte sorteringsalgoritmer en nedre grense p√• Œ©(ùëõ log ùëõ) i verste fall?","Sammenligningsbaserte sorteringsalgoritmer bestemmer rekkef√∏lgen av elementer kun ved √• sammenligne par av elementer. Det er bevist at i verste fall kreves det minst logaritmen av antall mulige permutasjoner (som er ùëõ!) for √• garantere at listen er sortert, og log‚ÇÇ(ùëõ!) er i Œ©(ùëõ log ùëõ).",,,
qa,"Lecture 2","Gi et eksempel p√• en operasjon som ikke regnes som et primitivt steg i kompleksitetsanalyse og forklar hvorfor.","Sammenligning eller konkatenering av strenger regnes vanligvis ikke som et primitivt steg. Dette er fordi operasjonene kan ta en tid som er proporsjonal med lengden p√• strengene, og dermed ikke en konstant tidsbruk uavhengig av inndatast√∏rrelsen.",,,
qa,"Lecture 2","Hva er et viktig hensyn √• ta n√•r man analyserer tidskompleksiteten til kode som bruker bibliotekfunksjoner?","N√•r man analyserer kode med bibliotekfunksjoner, er det viktig √• kjenne til (eller unders√∏ke) tidskompleksiteten til disse funksjonene. En enkelt linje kode som kaller en bibliotekfunksjon kan skjule en ikke-konstant tidsoperasjon, noe som p√•virker den totale kompleksiteten til algoritmen.",,,
qa,"Lecture 2","Beskriv ""bad painter's algorithm"" i forbindelse med strengkonkatenering i spr√•k med immutable strings.","""Bad painter's algorithm"" refererer til ineffektiv gjentatt konkatenering av strenger i spr√•k der strenger er immutable. Hver konkatenering skaper en ny streng og kopierer innholdet fra de gamle strengene, noe som f√∏rer til en kvadratisk tidskompleksitet (Œò(ùëõ¬≤)) hvis man gjentatte ganger legger til sm√• strenger til en stadig voksende streng.",,,
qa,"Lecture 2","Hva er den grunnleggende ideen bak amortisert tidskompleksitet, og i hvilke situasjoner kan det v√¶re en ulempe?","Amortisert tidskompleksitet beskriver den gjennomsnittlige kostnaden per operasjon over en sekvens av operasjoner, selv om enkelte individuelle operasjoner kan ha en h√∏yere kostnad. Dette oppst√•r ofte n√•r man dynamisk endrer st√∏rrelsen p√• datastrukturer, som for eksempel ved √• doble st√∏rrelsen p√• en array n√•r den er full. I sanntidssystemer med strenge tidsbegrensninger kan den variable kj√∏retiden til individuelle operasjoner v√¶re problematisk.",,,
qa,"Lecture 2","Nevn to eksempler p√• velkjente algoritmer eller datastrukturer (uten √• beskrive hvordan de fungerer) og forklar kort hvilke problemer de l√∏ser.","Et balansert bin√¶rt s√∏ketre er en datastruktur som tillater effektiv s√∏king, innsetting og sletting av elementer i logaritmisk tid. Dijkstras algoritme er en algoritme for √• finne den korteste stien fra en gitt startnode til alle andre noder i en vektet graf uten negative kantvekter.",,,
qa,"Lecture 3","Hva er en hashmap, og hvordan oppn√•r den ""nesten konstant"" tidskompleksitet for mange operasjoner?","En hashmap er en datastruktur som lagrer n√∏kler og tilh√∏rende verdier. Den bruker en hashfunksjon for √• beregne en indeks i et internt array basert p√• n√∏kkelen, noe som gir rask tilgang, innsetting og sletting i forventet konstant tid, selv om kollisjoner kan p√•virke ytelsen i verste fall.",,,
qa,"Lecture 3","Hvorfor er det viktig √• implementere __hash__ og __eq__ (i Python) eller hashCode() og equals() (i Java) n√•r man bruker egendefinerte k","Disse metodene er essensielle for at hashmaps skal fungere korrekt med egendefinerte n√∏kler. __hash__/hashCode() bestemmer hvor objektet skal plasseres, mens __eq__/equals() brukes til √• sjekke om to n√∏kler er like, spesielt ved kollisjoner. Konsistens mellom disse to er avgj√∏rende: like objekter m√• ha samme hashkode",,,
qa,"Lecture 3","Beskriv hvordan dybde-f√∏rst s√∏k (DFS) fungerer for √• traversere en graf.","DFS fungerer ved √• starte ved en node, bes√∏ke en av dens ubes√∏kte naboer, og deretter rekursivt fortsette fra den naboen. Den utforsker en ""sti"" s√• dypt som mulig f√∏r den backtracker til forrige node og utforsker en annen sti. For √• unng√• uendelige l√∏kker i grafer med sykluser, m√• algoritmen markere bes√∏kte noder.",,,
qa,"Lecture 3","Hva er hovedproblemet med en rekursiv implementasjon av DFS for sv√¶rt store grafer eller tr√¶r, og hvordan kan man omg√• dette problemet?","En rekursiv DFS-implementasjon kan f√∏re til stack overflow errors for store grafer eller tr√¶r fordi hvert rekursive kall legger til et nytt lag i call stacken, som har begrenset st√∏rrelse. Dette kan unng√•s ved √• implementere DFS iterativt ved hjelp av en eksplisitt stack data struktur (som en liste eller en dedikert stack-klasse) som administreres p√• heapen, som har mye st√∏rre kapasitet.",,,
qa,"Lecture 3","Forklar konseptet memoization og gi et eksempel p√• n√•r det er spesielt nyttig.","Memoization er en optimaliseringsteknikk for rekursive funksjoner der resultatet av kostbare funksjonskall lagres og gjenbrukes for samme input. Det er nyttig for problemer med overlappende subproblemer, for eksempel beregning av Fibonacci-tall rekursivt, der mange delberegninger gj√∏res flere ganger.",,,
qa,"Lecture 3","Gi et kort eksempel p√• en listekomprenasjon i Python og forklar dens tidskompleksitet i forhold til antall elementer den opererer p√•. Eksempel: [x*2 for x in numbers if x > 0].","Denne listekomprenasjonen g√•r gjennom alle elementene i numbers. Hvis betingelsen x > 0 er sann, utf√∏res transformasjonen x*2 og resultatet legges til i den nye listen. Hvis det er n elementer i numbers, og betingelsen og transformasjonen tar konstant tid, vil tidskompleksiteten v√¶re Œò(n).",,,
qa,"Lecture 3","Hva er dynamisk programmering (DP), og hvordan skiller det seg fra memoization i implementeringen?","Dynamisk programmering er en teknikk for √• l√∏se komplekse problemer ved √• bryte dem ned i overlappende subproblemer, l√∏se hvert subproblem bare √©n gang og lagre l√∏sningene i en tabell. Mens memoization typisk er en top-down tiln√¶rming (rekursivt med lagring), er DP ofte en bottom-up tiln√¶rming (iterativt, starter med de enkleste subproblemene).",,,
qa,"Lecture 3","Hvilken viktig egenskap kjennetegner NP-komplette problemer med hensyn til verifisering av en foresl√•tt l√∏sning?","En viktig egenskap ved NP-komplette problemer er at selv om det kan v√¶re vanskelig √• finne en l√∏sning, kan korrektheten av en gitt ""ja""-l√∏sning verifiseres i polynomisk tid. Dette betyr at hvis noen presenterer en mulig l√∏sning, kan vi relativt raskt sjekke om den faktisk er gyldig.",,,
qa,"Lecture 3","Nevn to eksempler p√• NP-komplette beslutningsproblemer som ble nevnt i kildematerialet.","To eksempler p√• NP-komplette beslutningsproblemer er Boolean satisfiability (SAT) og Subset sum. Andre inkluderer Subgraph isomorphism og Traveling salesperson.",,,
qa,"Lecture 3","Hva er den viktigste fordelen med generatorkomprehensjoner i Python og stream expressions i Java sammenlignet med listekomprenhensjoner n√•r det gjelder minnebruk og ytelse i visse situasjoner?","Generatorkomprehensjoner og stream expressions er ""lazy evaluated"", noe som betyr at de genererer elementer kun n√•r de ettersp√∏rres, i stedet for √• lage hele datastrukturen p√• forh√•nd. Dette kan v√¶re mer minneeffektivt, spesielt for store datasett, og kan forbedre ytelsen hvis ikke alle genererte elementene faktisk brukes.",,,
mc,"Lecture 4","Hvilken av f√∏lgende beskrivelser stemmer best for hvordan datamaskinens minne fremst√•r for et program?",,"En samling av ustrukturerte data uten spesifikke adresser.|En hierarkisk struktur organisert i segmenter med ulike form√•l.|En sammenhengende sekvens av bytes, der hver byte har sin egen adresse|Et abstrakt konsept uten direkte korrespondanse til fysisk maskinvare.",2,"For et program fremst√•r datamaskinens minne som en kontinuerlig rekke av bytes, hvor hver byte har sin egen unike adresse. Programmet er ansvarlig for √• tolke innholdet i disse bytene og holde styr p√• hvilken type data som er lagret hvor, samt hvor de ulike verdiene begynner og slutter. \n\nAlternativ 'En samling' er feil fordi minnet er adressert. \nAlternativ 'En hierarkisk' kan delvis v√¶re sant p√• et operativsystemniv√• med for eksempel segmentering, men for det enkelte programmet er det mer korrekt √• se det som en line√¶r sekvens. \nAlternativ 'Et abstrakt' er feil fordi minnet er fysisk maskinvare som programmet direkte interagerer med gjennom adresser."
mc,"Lecture 4","Hvor skjer automatisk minneallokering hovedsakelig?",,"P√• stakken for lokale variabler og funksjonsparametere|P√• heapen ved bruk av new-operatoren|I statisk allokert minne for globale variabler|I virtuelt minne administrert av operativsystemet",0,"Automatisk minneallokering skjer p√• stakken. N√•r en funksjon kalles, opprettes en stack frame som inneholder funksjonens parametere og lokale variabler. Denne allokeringen og deallokeringen skjer automatisk n√•r funksjonen henholdsvis kalles og returnerer. \n\nAlternativ 'P√• heapen' beskriver dynamisk minneallokering som foreg√•r p√• heapen ved bruk av new.\nAlternativ 'I statisk' beskriver statisk minneallokering for globale variabler.\nAlternativ 'I virtuelt' refererer til en minneh√•ndteringsteknikk p√• operativsystemniv√•, ikke en spesifikk plassering for automatisk allokering sett fra programmet."
mc,"Lecture 4","Hvilken operator i C++ brukes for √• f√• tilgang til verdien som en peker peker p√•?",,"&|.|->|**",3,"Operatoren som brukes for √• f√• tilgang til (hente verdien fra) minneadressen som en peker inneholder, kalles dereferanseoperatoren, og i C++ er dette *.\n\nAlternativ &, er adresseoperatoren som gir deg minneadressen til en variabel.\nAlternativ ., brukes for √• f√• tilgang til medlemmer av et objekt direkte.\nAlternativ ->, brukes for √• f√• tilgang til medlemmer av et objekt gjennom en peker til objektet."
mc,"Lecture 4","Hva er hoved√•rsaken til at en stack overflow kan oppst√•?",,"For mange dynamiske minneallokeringer p√• heapen.|Fors√∏k p√• √• dereferere en nullpeker.|For mange nestede eller rekursive funksjonskall som bruker opp all tilgjengelig minne i stakken|Fragmentering av minnet p√• heapen.",2,"En stack overflow oppst√•r n√•r call stacken blir full. Dette skjer typisk ved for mange nestede funksjonskall eller dype rekursive kall som gj√∏r at det allokeres for mange stack frames. Hver funksjonskall legger til en ny stack frame som inneholder parametere, lokale variabler og returadresse. Hvis disse kallene ikke returnerer i tide, vil stakken til slutt g√• tom for plass.\n\nAlternativ 'For mange dynamiske' handler om heapen.\nAlternativ 'Fors√∏k p√• √• dereferere' f√∏rer til et programkrasj p√• grunn av ugyldig minnetilgang, ikke n√∏dvendigvis en stack overflow.\nAlternativ 'Fragmentering' er et problem knyttet til minneh√•ndtering p√• heapen."
mc,"Lecture 4","Hva er en av hovedgrunnene til √• bruke pekere i programmering?",,"For √• unng√• √• jobbe direkte med minneadresser.|Fordi det er den eneste m√•ten √• deklarere variabler i C++.|For at en funksjon skal kunne modifisere den underliggende verdien av en variabel som er passert som argument|For √• sikre at all minneallokering skjer statisk.",2,"En viktig grunn til √• bruke pekere er muligheten for at en funksjon kan direkte endre verdien av en variabel som er sendt inn som et argument . Uten pekere ville funksjoner som regel jobbet med kopier av argumentene. Pekere tillater ogs√• mer effektiv h√•ndtering av store objekter ved √• sende en adresse i stedet for √• kopiere hele objektet . Videre er pekere essensielle for √• lage dynamiske datastrukturer som lenkede lister .\n\nAlternativ 'For √• unng√•' er feil, da pekere er direkte arbeid med minneadresser.\nAlternativ 'Fordi det er' er feil; det finnes mange m√•ter √• deklarere variabler uten pekere.\nAlternativ 'For √• sikre' er feil; pekere brukes ofte i forbindelse med dynamisk minneallokering."
qa,"Lecture 4","Forklar forskjellen mellom big endian og little endian.","Big endian betyr at byten med st√∏rst signifikans lagres f√∏rst i minnet (ved den laveste adressen), mens little endian betyr at byten med minst signifikans lagres f√∏rst.\nFor en 4-byte integer vil rekkef√∏lgen av bytene i minnet v√¶re omvendt mellom de to endianess-typene",,,
qa,"Lecture 4","Hva er en nullpeker i C++ og hvorfor kan den v√¶re farlig?","En nullpeker er en peker som ikke peker p√• et gyldig minneomr√•de. Den representeres som NULL eller nullptr i C++. Den er farlig fordi fors√∏k p√• √• dereferere (f√• tilgang til verdien som pekeren ""peker"" p√•) en nullpeker kan f√∏re til at programmet krasjer.",,,
qa,"Lecture 4","Beskriv hvordan dynamisk minne allokeres i C++ og hva new-operatoren returnerer.","I C++ allokerer man dynamisk minne ved √• bruke new-operatoren fulgt av typen man √∏nsker √• allokere, for eksempel new int eller new Person(...). new-operatoren returnerer en peker til det nylig allokerte minnet.",,,
qa,"Lecture 4","Hva er heapen og hvordan skiller den seg fra stakken med tanke p√• minneallokering og deallokering?","Heapen er et minneomr√•de for dynamisk allokerte verdier. I motsetning til stakken, som har en streng LIFO-struktur (sist inn, f√∏rst ut), kan verdier p√• heapen allokeres og deallokeres i vilk√•rlig rekkef√∏lge, noe som kan f√∏re til fragmentering. Stakken brukes for automatisk minneallokering av lokale variabler og funksjonsparametere n√•r en funksjon kalles.",,,
qa,"Lecture 4","Hvordan h√•ndteres konseptet ""referanse til ingenting"" i C++, Java og Python?","I C++ representeres en ""referanse til ingenting"" av en nullpeker (NULL eller nullptr). En C++-referanse i seg selv m√• initialiseres til √• referere til en eksisterende variabel og kan ikke v√¶re null. I Java representeres en ""referanse til ingenting"" med n√∏kkelordet null. I Python finnes ikke nullpekere; i stedet brukes objektet None for √• indikere en manglende referanse. Fors√∏k p√• √• bruke en nullpeker (C++) eller en nullreferanse (Java) kan f√∏re til programkrasj eller exceptions.",,,
qa,"Lecture 5","Hva er hovedforskjellen p√• hvordan minne allokeres for arrays i C++ og Java?","I C++ allokeres arrays opprettet med new p√• heapen, og array-variabelen er en peker til det f√∏rste elementet. I Java allokeres arrays alltid p√• heapen, og array-variabelen er en referanse til arrayen.",,,
qa,"Lecture 5","Hva er en minnelekkasje i C++?","En minnelekkasje i C++ oppst√•r n√•r dynamisk allokert minne med new (eller new[]) ikke blir frigjort med delete (eller delete[]) n√•r det ikke lenger er i bruk. Dette resulterer i at programmet gradvis bruker mer minne.",,,
qa,"Lecture 5","Hva er garbage collection og hva er en av dens viktigste fordeler?","Garbage collection er en automatisk minneh√•ndteringsteknikk der systemet periodisk identifiserer og frigj√∏r minne som ikke lenger er referert til av programmet. En viktig fordel er at den reduserer byrden for programmereren ved √• h√•ndtere minnefrigj√∏ring automatisk.",,,
qa,"Lecture 5","Hva er en destrukt√∏r i C++ og n√•r blir den kalt?","En destrukt√∏r i C++ er en spesiell medlemsfunksjon i en klasse med samme navn som klassen, men med en tilde (~) foran. Den kalles automatisk n√•r et objekt av klassen g√•r ut av scope eller blir deallokert med delete eller delete[].",,,
qa,"Lecture 5","Forklar kort hva romlig lokalitet er.","Romlig lokalitet refererer til tendensen til et program √• aksessere minnelokasjoner som er n√¶re hverandre i minnet innenfor en kort tidsperiode. CPU-cacher utnytter dette ved √• lagre n√¶rliggende data sammen.",,,
qa,"Lecture 5","Hvorfor kan sortering av data noen ganger f√∏re til raskere utf√∏relse av kode med betingelser i l√∏kker?","Sortering kan forbedre ytelsen fordi hvis de fleste elementene som oppfyller en betingelse kommer sammen, vil branch prediction i CPUen ha lettere for √• korrekt forutsi utfallet av betingelsen. Dette reduserer antall feilaktige forutsigelser og forbedrer dermed utf√∏relsestiden.",,,
mc,"Lecture 5","Hvor allokeres minne for arrays som opprettes dynamisk i C++?",,"P√• stakken.|P√• heapen|I statisk minne.|I CPU-cachen.",1,"I C++, arrays opprettet med new allokeres p√• heapen. \nStakken brukes hovedsakelig for lokale variabler og funksjonskall.\nStatisk minne brukes for globale variabler og variabler deklarert som static.\nCPU-cachen er et hurtigminne for nylig brukte data, ikke et sted for prim√¶r minneallokering."
mc,"Lecture 5","Hvilket av f√∏lgende er hovedform√•let med en destrukt√∏r i C++?",,"√Ö allokere minne for et objekt.|√Ö initialisere medlemsvariablene til et objekt.|√Ö frigj√∏re ressurser som et objekt har allokert.|√Ö definere grensesnittet til et objekt.",2,"Den prim√¶re form√•let med en destrukt√∏r i C++ er √• frigj√∏re ressurser, som for eksempel dynamisk allokert minne, som objektet har brukt.\nAllokering av minne gj√∏res vanligvis med konstrukt√∏rer eller new.\nInitialisering av medlemsvariabler er ogs√• en vanlig oppgave for konstrukt√∏rer.\n√Ö definere grensesnittet gj√∏res gjennom klassedeklarasjonen."
mc,"Lecture 5","Hva er den potensielle ulempen med garbage collection sammenlignet med manuell minneh√•ndtering?",,"St√∏rre risiko for minnelekkasjer.|Mer kompleks kode for minneh√•ndtering.|Potensielle korte pauser i utf√∏relsen.|Vanskeligere √• utnytte cache-lokalitet.",2,"En ulempe med garbage collection er potensielle korte pauser i utf√∏relsen mens s√∏ppelinnsamleren kj√∏rer.\n\nManuell minneh√•ndtering i C++ kan f√∏re til st√∏rre risiko for minnelekkasjer hvis det ikke gj√∏res korrekt.\nKompleksiteten ligger i √• h√•ndtere minnet selv, ikke n√∏dvendigvis i garbage collection.\nUtnyttelse av cache-lokalitet er mer relatert til hvordan data struktureres og aksesseres, ikke prim√¶rt til minneh√•ndteringsmetoden."
mc,"Lecture 5","Hva menes med tidslig lokalitet",,"Tendensen til √• aksessere minnelokasjoner som er langt fra hverandre i minnet.|Tendensen til √• aksessere minnelokasjoner i en bestemt rekkef√∏lge.|endensen til √• aksessere den samme minnelokasjonen flere ganger innenfor en kort tidsperiode.|Tendensen til √• allokere minne kun p√• stakken.",2,"Tidslig lokalitet refererer til tendensen til √• aksessere den samme minnelokasjonen flere ganger innenfor en kort tidsperiode. \nAlternativ 'minnelokasjoner som er langt fra hverandre' beskriver mangel p√• romlig lokalitet.\nAlternativ 'minnelokasjoner i en bestemt rekkef√∏lge' beskriver et aksessm√∏nster, men ikke n√∏dvendigvis tidslig lokalitet. \nAlternativ 'Tendensen til √• allokere' handler om minneallokering p√• stakken, ikke lokalitet."
mc,"Lecture 5","Hvorfor kan det oppst√• minnelekkasjer i spr√•k som bruker garbage collection?",,"Fordi garbage collectoren ikke fungerer korrekt.|Fordi minne allokert p√• stakken ikke blir frigjort.|Fordi programmet beholder referanser til objekter som ikke lenger er n√∏dvendige|Fordi destrukt√∏rer ikke kalles automatisk.",2,"Minnelekkasjer kan oppst√• selv med garbage collection hvis programmet beholder referanser til objekter eller arrays som ikke lenger er n√∏dvendige. Garbage collectoren frigj√∏r kun minne som ikke har noen aktive referanser. \n\nAlternativ ' ikke fungerer korrekt.' er usannsynlig i velfungerende systemer.\nAlternativ 'minne allokert p√• stakken ikke blir frigjort.' er ikke en typisk √•rsak til lekkasjer i spr√•k med garbage collection. \nAlternativ 'destrukt√∏rer ikke kalles' er relevant for C++, der manglende destrukt√∏rer kan f√∏re til ressurslekkasjer, men i spr√•k med garbage collection er problemet snarere at objektene fortsatt er ""i bruk"" s√• lenge det finnes referanser til dem."
mc,"Lecture 5","Hvilken konsekvens kan det ha √• aksessere en multidimensjonal array p√• en m√•te som ikke er cache-vennlig?",,"Raskere programutf√∏relse p√• grunn av mindre minnebruk.|Tregere programutf√∏relse p√• grunn av d√•rligere utnyttelse av CPU-cachen. |√òkt risiko for minnelekkasjer.|Kompilatoren vil optimalisere aksessm√∏nsteret automatisk.",1,"√Ö aksessere en multidimensjonal array p√• en ikke cache-vennlig m√•te kan f√∏re til tregere programutf√∏relse p√• grunn av d√•rligere utnyttelse av CPU-cachen. N√•r aksessm√∏nsteret ikke f√∏lger den fysiske layouten i minnet, vil CPUen oftere m√•tte hente data fra hovedminnet i stedet for den raskere cachen. Dette √∏ker minnetilgangstiden og reduserer ytelsen. \n\nAlternativ 'Raskere programutf√∏relse' er feil da d√•rlig cache-bruk vanligvis ikke reduserer minnebruken. \nAlternativ '√òkt risiko' er ikke direkte relatert til cache-bruk. \nAlternativ 'Kompilatoren ' er ikke alltid tilfelle; programmereren m√• ofte ta hensyn til cache-effektivitet i koden."
qa,"Lecture 6","Hva er hovedforskjellen p√• hvordan bibliotekkode inkluderes ved statisk og dynamisk linking?","Ved statisk linking kopieres bibliotekkoden direkte inn i den kj√∏rbare filen under kompilering. Ved dynamisk linking lagres bibliotekskoden i separate delte bibliotekfiler, og operativsystemet laster dem inn i minnet n√•r programmet kj√∏rer.",,,
qa,"Lecture 6","Nevn √©n fordel med statisk linking og √©n fordel med dynamisk linking.","En fordel med statisk linking er at den kj√∏rbare filen inneholder all n√∏dvendig kode og dermed er mer portabel. En fordel med dynamisk linking er at diskplass spares fordi delte biblioteker bare lagres √©n gang.",,,
qa,"Lecture 6","Hvilke tre standardstr√∏mmer stiller operativsystemet til r√•dighet for en prosess, og hva er deres prim√¶re bruksomr√•der?","De tre standardstr√∏mmene er stdin (standard input) for inndata til programmet (vanligvis tastatur), stdout (standard output) for normal utdata fra programmet (vanligvis terminal), og stderr (standard error) for feilmeldinger fra programmet (ogs√• vanligvis terminal).",,,
qa,"Lecture 6","Hva indikerer en statuskode p√• 0 n√•r et program avsluttes i henhold til Linux-konvensjonen, og hvordan kan man spesifisere en annen statuskode i Python?","En statuskode p√• 0 indikerer at programmet ble utf√∏rt uten feil. I Python kan man spesifisere en annen statuskode ved √• bruke sys.exit(x) hvor x er den √∏nskede koden.",,,
qa,"Lecture 6","Forklar kort hensikten med `extern ""C""` i C++.","Hensikten med `extern ""C""` i C++ er √• hindre navnemangling (name mangling) for spesifikke funksjoner. Dette gj√∏r at C++-funksjoner kan kalles fra C-kode eller andre spr√•k som forventer C-stil funksjonsnavn.",,,
qa,"Lecture 6","Hva er Java Native Interface (JNI) og hva er Foreign Function & Memory API (FFM API) i Java?","Java Native Interface (JNI) er en mekanisme som gj√∏r det mulig for Java-kode √• samhandle med kode skrevet i andre spr√•k som C og C++. Foreign Function & Memory API (FFM API) er et nyere system i Java som forenkler interaksjonen med kode utenfor JVM.",,,
mc,"Lecture 6","Hvilket begrep beskriver prosessen der bibliotekkode kopieres direkte inn i den kj√∏rbare filen under kompilering?",,"Dynamisk linking|Statisk linking|Lasting|Kompilering",1,"Statisk linking er definert som prosessen der kompilatoren kopierer og kombinerer all n√∏dvendig bibliotekkode direkte inn i den endelige kj√∏rbare filen under kompilering.\n\nAlternativ 'Dynamisk linking' refererer til at koblingen til bibliotekkode utsettes til kj√∏retid. \nAlternativ 'Lasting' er prosessen der operativsystemet henter den kj√∏rbare filen (og eventuelle dynamiske biblioteker) inn i minnet ved kj√∏retid. \nAlternativ 'Kompilering' er prosessen med √• oversette kildekode til objektkode."
mc,"Lecture 6","Hvilken av f√∏lgende er en potensiell ulempe med statisk linking?",,"√òkt avhengighet av eksterne biblioteker ved kj√∏retid.|St√∏rre kj√∏rbare filer som kan f√∏re til sl√∏sing av diskplass.|Tiden det tar √• starte programmet √∏ker.|Vanskeligere √• oppdatere biblioteker.",1,"En ulempe med statisk linking er at den kj√∏rbare filen blir st√∏rre, og at diskplass sl√∏ses hvis mange programmer bruker det samme biblioteket.\n\nAlternativ '√òkt avhengighet av eksterne biblioteker ved kj√∏retid' er en ulempe med dynamisk linking. \nAlternativ 'Tiden det tar √• starte programmet √∏ker' er mer relatert til lasting av mange dynamiske biblioteker eller oppstart av nye prosesser.\nAlternativ 'Vanskeligere √• oppdatere biblioteker' er ogs√• en ulempe med statisk linking fordi man m√• rekompilere og redistribuere alle applikasjoner som bruker biblioteket n√•r det oppdateres."
mc,"Lecture 6","Hvilken standardstr√∏m brukes vanligvis for √• sende feilmeldinger fra et program?",,"stdin|stdout|stderr|stdlog",2,"stderr (standard error) er standardstr√∏mmen som brukes for feilmeldinger fra programmet.\n\nAlternativ 'stdin (standard input)' brukes for inndata til programmet.\nAlternativ 'stdout (standard output)' brukes for normal utdata fra programmet.\nAlternativ 'stdlog' er ikke en av de tre standardstr√∏mmene som operativsystemet gir til en prosess ved oppstart."
mc,"Lecture 6","Hva indikerer vanligvis en statuskode (exit code) forskjellig fra 0 n√•r et program avsluttes?",,"Programmet har fullf√∏rt uten problemer.|Programmet ble tvangsavsluttet av brukeren.|Det har oppst√•tt en feil under utf√∏relsen av programmet.|Programmet venter fortsatt p√• inndata.",2,"En statuskode forskjellig fra 0 indikerer konvensjonelt at det har oppst√•tt en feil under utf√∏relsen av programmet. En statuskode p√• 0 indikerer at programmet ble utf√∏rt uten feil.\n\nAlternativ 'Programmet har fullf√∏rt uten problemer' tilsvarer en statuskode p√• 0.\nAlternativ 'Programmet ble tvangsavsluttet av brukeren' kan resultere i en statuskode forskjellig fra 0, men det er mer spesifikt en √•rsak til feil eller avbrudd.\nAlternativ 'Programmet venter fortsatt p√• inndata' betyr at programmet ikke har avsluttet enn√• og vil derfor ikke ha returnert en statuskode."
mc,"Lecture 6","Hvilken funksjonalitet i C++ brukes for √• sikre at C++-funksjoner kan kalles direkte fra C-kode?",,"Navnemangling|Klasser|Templating|extern ""C""",3,"`extern ""C""` brukes i C++ for √• hindre navnemangling. Dette er n√∏dvendig for at funksjonsnavnene skal v√¶re kompatible med C-koblingskonvensjoner, slik at C-kode kan finne og kalle C++-funksjoner. \n\nAlternativ 'Navnemangling' er prosessen som extern ""C"" fors√∏ker √• unng√• i dette tilfellet.\nAlternativ 'Klasser' og 'Templating' er andre viktige konsepter i C++, men de er ikke direkte relatert til kompatibilitet med C-kobling p√• denne m√•ten."
mc,"Lecture 6","Hvilken av f√∏lgende er en potensiell ulempe ved √• starte en ny prosess for √• utf√∏re kode i et annet spr√•k?",,"Bedre minneh√•ndtering.|√òkt sikkerhet p√• grunn av prosessisolering.|Tidsforsinkelse p√• grunn av oppstart og administrasjon av den nye prosessen.|Enklere deling av ressurser.",2,"En potensiell ulempe ved √• starte en ny prosess er at det tar tid √• starte en ny prosess p√• grunn av at den kj√∏rbare filen m√• lastes inn i minnet og operativsystemet m√• utf√∏re administrasjon. Dette kan f√∏re til tidsforsinkelse, spesielt ved hyppig kj√∏ring av sm√• kodebiter. \n\nAlternativ 'Bedre minneh√•ndtering' kan v√¶re en fordel i visse tilfeller p√• grunn av prosessisolering, men er ikke en generell ulempe ved oppstart.\nAlternativ '√òkt sikkerhet p√• grunn av prosessisolering' er en fordel, ikke en ulempe.\nAlternativ 'Enklere deling av ressurser' er ikke n√∏dvendigvis en direkte konsekvens eller fordel ved √• starte en ny prosess for kode i et annet spr√•k; deling av ressurser mellom prosesser krever spesifikke mekanismer."
qa,"Lecture 7","Hva betyr det for et program √• √•pne en fil, og hvorfor er det viktig √• lukke filh√•ndtaket n√•r man er ferdig?","√Ö √•pne en fil betyr at programmet ber operativsystemet om √• finne filen og opprette en ""forbindelse"" (filh√•ndtak/fildeskriptor). Det er viktig √• lukke filh√•ndtaket n√•r man er ferdig for √• frigj√∏re systemressurser og unng√• ressurslekkasjer, da det er en grense for hvor mange filh√•ndtak et program kan ha √•pent samtidig.",,,
qa,"Lecture 7","Nevn de tre standardstr√∏mmene som ethvert prosess mottar fra operativsystemet ved oppstart, og beskriv kort hva hver av dem brukes til.","De tre standardstr√∏mmene er stdin (standard input) for inndata fra brukeren eller en annen prosess, stdout (standard output) for vanlige utdata til brukeren eller en annen prosess, og stderr (standard error) for feilmeldinger.",,,
qa,"Lecture 7","Hva er hovedforskjellen mellom sekvensiell og tilfeldig (random) filtilgang, og hvilken type er generelt raskere for diskoperasjoner?","Sekvensiell filtilgang betyr √• lese eller skrive data i rekkef√∏lge, fra begynnelsen til slutten, mens tilfeldig filtilgang betyr √• f√• tilgang til data i en vilk√•rlig rekkef√∏lge ved √• bruke ""seek""-operasjoner. Sekvensiell tilgang er generelt raskere fordi disken kan lese sammenhengende blokker mer effektivt.",,,
qa,"Lecture 7","Forklar kort hva en diskcache er og hvorfor man m√• kalle sync() i visse situasjoner.","En diskcache er en mekanisme i operativsystemet som lagrer nylig leste eller skrivne diskblokker i minnet. Dette gj√∏r at fremtidige tilganger til de samme dataene kan skje raskere fra minnet i stedet for den tregere disken. Man m√• kalle sync() for √• v√¶re absolutt sikker p√• at data som er skrevet har blitt fysisk lagret p√• disken, da data f√∏rst kan ligge i diskcachen.",,,
qa,"Lecture 7","Hva er Unicode, og hva er hensikten med det? Nevn minst to vanlige UTF-enkodinger.","Unicode er et omfattende tegnesett som har som m√•l √• definere et unikt kodeunkt for de fleste tegn i alle skriftlige menneskelige spr√•k. To vanlige UTF-enkodinger inkluderer UTF-8 (variabel lengde, 1-4 bytes per tegn) og UTF-16 (vanligvis 2 eller 4 bytes per tegn).",,,
qa,"Lecture 7","Forklar kort hvordan en with-setning i Python bidrar til √• unng√• lekkasjer av filh√•ndtak.","En with-setning i Python sikrer at en ressurs (som en fil) blir korrekt h√•ndtert, spesielt med tanke p√• lukking. Objektet som brukes med with er en ""context manager"" som har metoder for √• tre i kraft ved inngangen (__enter__) og utgangen (__exit__) av blokken. Selv om det oppst√•r en feil inne i with-blokken, vil __exit__-metoden (som for filer inkluderer lukking) alltid bli kj√∏rt.",,,
mc,"Lecture 7","Hva er den prim√¶re funksjonen til et filh√•ndtak(fildeskriptor)? Svaralternativer:",,"√Ö lagre innholdet i en fil permanent p√• disken.|√Ö gi et program en abstrakt m√•te √• identifisere og samhandle med en √•pen fil administrert av operativsystemet.|√Ö kryptere innholdet i en fil for sikker lagring.|√Ö komprimere filst√∏rrelsen for √• spare diskplass.",1,"Et filh√•ndtak (ogs√• kalt fildeskriptor) er en abstrakt indikator som operativsystemet bruker for √• identifisere en √•pen fil. Det er denne indikatoren programmet bruker for √• utf√∏re operasjoner som lesing og skriving.\n\nAlternativet om permanent lagring beskriver filsystemets generelle funksjon. Kryptering og komprimering er separate prosesser som ikke er direkte knyttet til filh√•ndtakets prim√¶re funksjon."
mc,"Lecture 7","Hvorfor strukturerer databaser data i indekser ved hjelp av trestrukturer eller hash-tabeller?",,"For √• redusere det totale datavolumet som m√• lagres p√• disken.|For √• sikre at dataene lagres i kronologisk rekkef√∏lge basert p√• innsettingstidspunktet.|For √• raskt kunne lokalisere spesifikke data p√• disken ved √• minimere antall diskoperasjoner.|For √• optimalisere sekvensiell lesing av data i store tabeller.",2,"Indekser basert p√• trestrukturer (som B-tr√¶r) eller hash-tabeller brukes av databaser for √• raskt finne spesifikke data. Disse strukturene er optimalisert for diskoperasjoner ved √• organisere data slik at f√¶rrest mulig diskaksesser er n√∏dvendig for √• finne den √∏nskede informasjonen. Datakomprimering er ikke indeksenes prim√¶re form√•l, rekkef√∏lgen av data i indeksen er logisk basert p√• n√∏kkelverdier, og indekser er prim√¶rt for raske oppslag, ikke optimalisering av sekvensiell lesing."
mc,"Lecture 7","Hva er hovedideen bak ekstern sortering n√•r man har data som ikke f√•r plass i minnet?",,"√Ö bruke mer av prosessorens cache for √• h√•ndtere de store datamengdene.|√Ö dele dataene opp i mindre biter som kan sorteres individuelt i minnet og deretter sl√•s sammen ved hjelp av disk I/O.|√Ö dynamisk √∏ke st√∏rrelsen p√• hovedminnet ved bruk av diskplass som virtuelt minne.|√Ö komprimere dataene f√∏r sortering for √• redusere minnebruken under sorteringsprosessen.",1,"Ekstern sortering brukes n√•r data er for stort til √• passe i minnet. Ideen er √• dele dataene opp i h√•ndterbare biter, sortere hver bit i minnet, og deretter sl√• sammen de sorterte bitene til en endelig sortert fil ved hjelp av disk I/O.\n\nSelv om √∏kt bruk av cache kan hjelpe, er ikke det hovedideen.\nVirtuelt minne h√•ndteres av operativsystemet og l√∏ser ikke n√∏dvendigvis problemet med store datasett i minnet for en sorteringsalgoritme.\nKomprimering kan redusere st√∏rrelsen, men l√∏ser sjelden problemet med at dataene er fundamentalt for store for minnet under sortering."
mc,"Lecture 7","Hva er den grunnleggende forskjellen mellom en streng og en byte-array i databehandling?",,"En streng kan bare inneholde numeriske verdier, mens en byte-array kan inneholde tekstdata.|En streng er en sekvens av tegn, mens en byte-array er en sekvens av numeriske byte-verdier.|En streng er lagret direkte p√• disken som en fil, mens en byte-array er kun i minnet.|Det er ingen fundamental forskjell; begrepene brukes synonymt i de fleste programmeringsspr√•k.",1,"En streng representerer tekst som en sekvens av tegn, der hvert tegn har en abstrakt representasjon (kodeunkt). En byte-array derimot, er en lavniv√•representasjon av bin√¶re data, hvor hvert element er en numerisk byte-verdi. Konvertering mellom de to krever bruk av en tegnekoding."
mc,"Lecture 7","Hvorfor er tegnesett og tegnekoding n√∏dvendig n√•r man arbeider med tekst i datamaskiner?",,"For √• sikre at tekstdata tar mindre plass ved lagring og overf√∏ring.|For √• kunne konvertere mellom menneskelig lesbar tekst (tegn) og maskinens bin√¶re representasjon (bytes).|For √• kryptere tekstdata slik at de ikke kan leses av uvedkommende.|For √• optimalisere hastigheten p√• teksts√∏k i store dokumenter.",1,"Et tegnesett definerer hvilke tegn som finnes og gir hvert tegn en unik kode (kodeunkt). En tegnekoding definerer hvordan disse kodeunktene representeres som en sekvens av bits (bytes) for lagring og overf√∏ring. Uten dette systemet ville datamaskiner ikke kunne tolke og vise tekst korrekt.\nKomprimering og kryptering er separate prosesser, og selv om tegnesett og koding indirekte kan p√•virke s√∏kehastighet ved √• bestemme datastrukturen, er ikke det deres prim√¶re n√∏dvendighet."
mc,"Lecture 7","Hvilken viktig fordel gir bruken av en with-setning (eller tilsvarende konstruksjoner) ved h√•ndtering av filer sammenlignet med manuell √•pning og lukking?",,"Den gj√∏r filoperasjoner raskere ved √• optimalisere disk I/O.|Den sikrer at filen lukkes automatisk, selv om det oppst√•r feil (unntak) i kodeblokken.|Den gir bedre kontroll over filens tilgangsrettigheter.|Den reduserer minnebruken ved h√•ndtering av store filer.",1,"En with-setning (og lignende konstruksjoner som try-with-resources i Java og smarte pekere i C++) er utformet for √• automatisere ressursh√•ndtering, spesielt lukking av filer. Selv om det oppst√•r en feil inne i blokken, vil ressursen bli korrekt frigjort. Dette bidrar til √• unng√• ressurslekkasjer.\nSelv om korrekt lukking er viktig for ytelsen og kan indirekte p√•virke minnebruk, er den prim√¶re fordelen den garanterte lukkingen ogs√• ved feil. Kontroll over tilgangsrettigheter h√•ndteres p√• et annet niv√•."
